{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+zSupwROFrbKzYyCrw2fn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meirbelo/gapevine_dataset/blob/main/officialModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "6UUWI9EpQcjQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)  # Rééchelonne les images\n",
        "\n",
        "# Créer le générateur pour l'ensemble d'entraînement\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=\"/content/repartition/train\",\n",
        "    target_size=(224, 224),  # Taille des images après redimensionnement\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Utilisez \"categorical\" pour plusieurs classes\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Créer le générateur pour l'ensemble de validation\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)  # Rééchelonne les images\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    directory=\"/content/repartition/validation\",\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Utilisez \"categorical\" pour plusieurs classes\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Créer le générateur pour l'ensemble de test\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rééchelonne les images\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=\"/content/repartition/test\",\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Utilisez \"categorical\" pour plusieurs classes\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EhjQVhLQgqK",
        "outputId": "349e8d44-e54e-4b6d-b97d-c8952b260847"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le modèle VGG16 pré-entraîné sur ImageNet et sans la dernière couche de classification\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Ajouter une nouvelle couche de classification binaire\n",
        "x = base_model.output\n",
        "x = Flatten()(x)  # Aplatir la sortie du modèle de base\n",
        "x = Dense(512, activation='relu')(x)  # Ajouter une couche dense intermédiaire pour améliorer l'expressivité du modèle\n",
        "x = Dropout(0.2)(x)  # Ajouter un Dropout pour réduire le surapprentissage\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Ajouter une couche dense de sortie pour la classification binaire\n",
        "\n",
        "# Définir le modèle final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Congeler les couches du modèle de base pour ne pas les entraîner\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Entraîner le modèle avec les générateurs d'images\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // train_generator.batch_size,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Évaluer le modèle sur l'ensemble de test\n",
        "scores = model.evaluate(\n",
        "    test_generator,\n",
        "    steps = test_generator.samples // test_generator.batch_size\n",
        ")\n",
        "\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZtRz7R7Qjm7",
        "outputId": "8c15f8a5-0299-4ec9-996c-92155ede695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "111/437 [======>.......................] - ETA: 1:46:54 - loss: 0.9590 - accuracy: 0.5000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualiser l'historique de l'entraînement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Afficher la courbe de la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history.history['loss'], label='Perte (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Perte (validation data)')\n",
        "plt.title('Perte pour la classification des feuilles de vigne')\n",
        "plt.ylabel('Perte')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# Afficher la courbe de la précision\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history.history['accuracy'], label='Précision (training data)')\n",
        "plt.plot(history.history['val_accuracy'], label='Précision (validation data)')\n",
        "plt.title('Précision pour la classification des feuilles de vigne')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c7cMIygNQmqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Charger l'ensemble de données de test\n",
        "test_path = \"/content/repartition/test\"\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Effectuer les prédictions sur l'ensemble de données de test\n",
        "predicted_labels = []\n",
        "for images, _ in test_ds:\n",
        "    predictions = efficientnetb0.predict(images)\n",
        "    predicted_labels_batch = np.argmax(predictions, axis=1)\n",
        "    predicted_labels.extend(predicted_labels_batch)\n",
        "\n",
        "# Convertir les étiquettes prédites en noms de classes\n",
        "predicted_labels = encoder.inverse_transform(\"/home/meir/Epitech/ia/voltron/repartition/test\")\n",
        "\n",
        "# Afficher les étiquettes prédites\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "id": "xyt9_MnAQm57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}